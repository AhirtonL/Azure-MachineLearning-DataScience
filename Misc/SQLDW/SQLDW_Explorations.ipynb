{"nbformat_minor": 0, "cells": [{"source": "# License Information", "cell_type": "markdown", "metadata": {}}, {"source": "This sample IPython Notebook is shared by Microsoft under the MIT license. Please check the LICENSE.txt file in the directory where this  IPython Notebook is stored for license information and additional details.", "cell_type": "raw", "metadata": {}}, {"source": "# NYC Data wrangling using IPython Notebook and SQL Data Warehouse", "cell_type": "markdown", "metadata": {}}, {"source": "This notebook demonstrates data exploration and feature generation using Python and SQL queries for data stored in Azure SQL Data Warehouse. We start with reading a sample of the data into a Pandas data frame and visualizing and exploring the data. We show how to use Python to execute SQL queries against the data and manipulate data directly within the Azure SQL Data Warehouse.\n\nThis IPNB is accompanying material to the data Azure Data Science in Action walkthrough document (https://azure.microsoft.com/en-us/documentation/articles/machine-learning-data-science-process-sql-walkthrough/) and uses the New York City Taxi dataset (http://www.andresmh.com/nyctaxitrips/).", "cell_type": "markdown", "metadata": {}}, {"source": "## Read data in Pandas frame for visualizations", "cell_type": "markdown", "metadata": {}}, {"source": "We start with loading a sample of the data in a Pandas data frame and performing some explorations on the sample. \n\nWe join the Trip and Fare data and sub-sample the data to load a 0.1% sample of the dataset in a Pandas dataframe. We assume that the Trip and Fare tables have been created and loaded from the taxi dataset mentioned earlier. If you haven't done this already please refer to the 'Move Data to SQL Server on Azure' article linked from the Cloud Data Science process map.", "cell_type": "markdown", "metadata": {}}, {"source": "#### Import required packages in this experiment", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "import pandas as pd\nfrom pandas import Series, DataFrame\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom time import time\nimport pyodbc\nimport os\nimport tables\nimport time", "outputs": [], "metadata": {"collapsed": false}}, {"source": "#### Set plot inline", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "%matplotlib inline", "outputs": [], "metadata": {"collapsed": false}}, {"source": "#### Initialize Database Credentials", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "SERVER_NAME = '<server name>'\nDATABASE_NAME = '<database name>'\nUSERID = '<user name>'\nPASSWORD = '<password>'\nDB_DRIVER = '<database driver>'", "outputs": [], "metadata": {"collapsed": false}}, {"source": "#### Create Database Connection", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "driver = 'DRIVER={' + DB_DRIVER + '}'\nserver = 'SERVER=' + SERVER_NAME \ndatabase = 'DATABASE=' + DATABASE_NAME\nuid = 'UID=' + USERID \npwd = 'PWD=' + PASSWORD", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "CONNECTION_STRING = ';'.join([driver,server,database,uid,pwd, ';TDS_VERSION=7.3;Port=1433'])\nprint CONNECTION_STRING\nconn = pyodbc.connect(CONNECTION_STRING)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "#### Report number of rows and columns in table <nyctaxi_trip>", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "nrows = pd.read_sql('''SELECT SUM(rows) FROM sys.partitions WHERE object_id = OBJECT_ID('<schemaname>.<nyctaxi_trip>')''', conn)\nprint 'Total number of rows = %d' % nrows.iloc[0,0]\n\nncols = pd.read_sql('''SELECT count(*) FROM information_schema.columns WHERE table_name = ('<nyctaxi_trip>') AND and table_schema = '<schemaname>''', conn)\nprint 'Total number of columns = %d' % ncols.iloc[0,0]", "outputs": [], "metadata": {"collapsed": false}}, {"source": "#### Report number of rows and columns in table \\<nyctaxi_fare>", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "nrows = pd.read_sql('''SELECT SUM(rows) FROM sys.partitions WHERE object_id = OBJECT_ID('<schemaname>.<nyctaxi_fare>')''', conn)\nprint 'Total number of rows = %d' % nrows.iloc[0,0]\n\nncols = pd.read_sql('''SELECT count(*) FROM information_schema.columns WHERE table_name = ('<nyctaxi_fare>') AND and table_schema = '<schemaname>''', conn)\nprint 'Total number of columns = %d' % ncols.iloc[0,0]", "outputs": [], "metadata": {"collapsed": false}}, {"source": "#### Read-in data from SQL Data Warehouse", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "t0 = time.time()\n\n#load only a small percentage of the joined data for some quick visuals\ndf1 = pd.read_sql('''select top 10000 t.*, f.payment_type, f.fare_amount, f.surcharge, f.mta_tax, \n      f.tolls_amount, f.total_amount, f.tip_amount \n      from <schemaname>.<nyctaxi_trip> t, <schemaname>.<nyctaxi_fare> f where datepart(\"mi\",t.pickup_datetime)=0 and t.medallion = f.medallion \n      and t.hack_license = f.hack_license and t.pickup_datetime = f.pickup_datetime''', conn)\n\nt1 = time.time()\nprint 'Time to read the sample table is %f seconds' % (t1-t0)\n\nprint 'Number of rows and columns retrieved = (%d, %d)' % (df1.shape[0], df1.shape[1])", "outputs": [], "metadata": {"collapsed": false}}, {"source": "#### Descriptive Statistics", "cell_type": "markdown", "metadata": {}}, {"source": "Now we can explore the sample data. We start with looking at descriptive statistics for trip distance:", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "df1['trip_distance'].describe()", "outputs": [], "metadata": {"collapsed": false}}, {"source": "#### Box Plot", "cell_type": "markdown", "metadata": {}}, {"source": "Next we look at the box plot for trip distance to visualize quantiles", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "df1.boxplot(column='trip_distance',return_type='dict')", "outputs": [], "metadata": {"collapsed": false}}, {"source": "#### Distribution Plot", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "fig = plt.figure()\nax1 = fig.add_subplot(1,2,1)\nax2 = fig.add_subplot(1,2,2)\ndf1['trip_distance'].plot(ax=ax1,kind='kde', style='b-')\ndf1['trip_distance'].hist(ax=ax2, bins=100, color='k')", "outputs": [], "metadata": {"collapsed": false}}, {"source": "#### Binning trip_distance", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "trip_dist_bins = [0, 1, 2, 4, 10, 1000]\ndf1['trip_distance']\ntrip_dist_bin_id = pd.cut(df1['trip_distance'], trip_dist_bins)\ntrip_dist_bin_id", "outputs": [], "metadata": {"collapsed": false}}, {"source": "#### Bar and Line Plots", "cell_type": "markdown", "metadata": {}}, {"source": "The distribution of the trip distance values after binning looks like the following:", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "pd.Series(trip_dist_bin_id).value_counts()", "outputs": [], "metadata": {"collapsed": false}}, {"source": "We can plot the above bin distribution in a bar or line plot as below", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "pd.Series(trip_dist_bin_id).value_counts().plot(kind='bar')", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "pd.Series(trip_dist_bin_id).value_counts().plot(kind='line')", "outputs": [], "metadata": {"collapsed": false}}, {"source": "We can also use bar plots for visualizing the sum of passengers for each vendor as follows", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "vendor_passenger_sum = df1.groupby('vendor_id').passenger_count.sum()\nprint vendor_passenger_sum", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "vendor_passenger_sum.plot(kind='bar')", "outputs": [], "metadata": {"collapsed": false}}, {"source": "#### Scatterplot ", "cell_type": "markdown", "metadata": {}}, {"source": "We plot a scatter plot between trip_time_in_secs and trip_distance to see if there is any correlation between them.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "plt.scatter(df1['trip_time_in_secs'], df1['trip_distance'])", "outputs": [], "metadata": {"collapsed": false}}, {"source": "To further drill down on the relationship we can plot distribution side by side with the scatter plot (while flipping independentand dependent variables) as follows", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "df1_2col = df1[['trip_time_in_secs','trip_distance']]\npd.scatter_matrix(df1_2col, diagonal='hist', color='b', alpha=0.7, hist_kwds={'bins':100})", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Similarly we can check the relationship between rate_code and trip_distance using a scatter plot", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "plt.scatter(df1['passenger_count'], df1['trip_distance'])", "outputs": [], "metadata": {"collapsed": false}}, {"source": "#### Correlation", "cell_type": "markdown", "metadata": {}}, {"source": "Pandas 'corr' function can be used to compute the correlation between trip_time_in_secs and trip_distance as follows:", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "df1[['trip_time_in_secs', 'trip_distance']].corr()", "outputs": [], "metadata": {"collapsed": false}}, {"source": "## Sub-Sampling the Data in SQL", "cell_type": "markdown", "metadata": {}}, {"source": "In this section we used a sampled table we pregenerated by joining Trip and Fare data and taking a sub-sample of the full dataset. \n\nThe sample data table named '<nyctaxi_sample>' has been created and the data is loaded when you run the PowerShell script. ", "cell_type": "markdown", "metadata": {}}, {"source": "#### Report number of rows and columns in the sampled table", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "nrows = pd.read_sql('''SELECT SUM(rows) FROM sys.partitions WHERE object_id = OBJECT_ID('<schemaname>.<nyctaxi_sample>')''', conn)\nprint 'Number of rows in sample = %d' % nrows.iloc[0,0]\n\nncols = pd.read_sql('''SELECT count(*) FROM information_schema.columns WHERE table_name = ('<nyctaxi_sample>') AND and table_schema = '<schemaname>''', conn)\nprint 'Number of columns in sample = %d' % ncols.iloc[0,0]", "outputs": [], "metadata": {"collapsed": false}}, {"source": "We show some examples of exploring data using SQL in the sections below. We also show some useful visualizatios that you can use below. Note that you can read the sub-sample data in the table above in Azure Machine Learning directly using the SQL code in the reader module. ", "cell_type": "markdown", "metadata": {}}, {"source": "## Exploration in SQL", "cell_type": "markdown", "metadata": {}}, {"source": "In this section, we would be doing some explorations using SQL on the 1% sample data (that we created above).", "cell_type": "markdown", "metadata": {}}, {"source": "#### Tipped/Not Tipped Distribution", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "query = '''\n        SELECT tipped, count(*) AS tip_freq\n        FROM <schemaname>.<nyctaxi_sample>\n        GROUP BY tipped\n        '''\n\npd.read_sql(query, conn)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "#### Tip Class Distribution", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "query = '''\n        SELECT tip_class, count(*) AS tip_freq\n        FROM <schemaname>.<nyctaxi_sample>\n        GROUP BY tip_class\n'''\n\ntip_class_dist = pd.read_sql(query, conn)\ntip_class_dist", "outputs": [], "metadata": {"collapsed": false}}, {"source": "#### Plot the tip distribution by class", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "tip_class_dist['tip_freq'].plot(kind='bar')", "outputs": [], "metadata": {"collapsed": false}}, {"source": "#### Daily distribution of trips", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "query = '''\n        SELECT CONVERT(date, dropoff_datetime) as date, count(*) as c \n        from <schemaname>.<nyctaxi_sample> \n        group by CONVERT(date, dropoff_datetime)\n        '''\npd.read_sql(query,conn)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "#### Trip distribution per medallion", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "query = '''select medallion,count(*) as c from <schemaname>.<nyctaxi_sample> group by medallion'''\npd.read_sql(query,conn)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "#### Trip distribution by medallion and hack license", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "query = '''select medallion, hack_license,count(*) from <schemaname>.<nyctaxi_sample> group by medallion, hack_license'''\npd.read_sql(query,conn)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "#### Trip time distribution", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "query = '''select trip_time_in_secs, count(*) from <schemaname>.<nyctaxi_sample> group by trip_time_in_secs order by count(*) desc'''\npd.read_sql(query,conn)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "#### Trip distance distribution", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "query = '''select floor(trip_distance/5)*5 as tripbin, count(*) from <schemaname>.<nyctaxi_sample> group by floor(trip_distance/5)*5 order by count(*) desc'''\npd.read_sql(query,conn)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "#### Payment type distribution", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "query = '''select payment_type,count(*) from <schemaname>.<nyctaxi_sample> group by payment_type'''\npd.read_sql(query,conn)", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "query = '''select TOP 10 * from <schemaname>.<nyctaxi_sample>'''\npd.read_sql(query,conn)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "We have now explored the data and can import the sampled data in Azure Machine Learning, add some features there and  predict things like whether a tip will be given (binary class), the tip amount (regression) or the tip amount range (multi-class)", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {"collapsed": false}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Python 2", "name": "python2", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "2.7.10", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython2", "codemirror_mode": {"version": 2, "name": "ipython"}}}}